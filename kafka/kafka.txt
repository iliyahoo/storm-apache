systemctl stop firewalld
systemctl disable firewalld

# install java
yum install -y java-1.8.0-openjdk

wget http://apache.mivzakim.net/kafka/0.8.2.1/kafka_2.9.1-0.8.2.1.tgz
tar -xvf kafka_2.9.1-0.8.2.1.tgz
mv kafka_2.9.1-0.8.2.1 /srv/
ln -s /srv/kafka_2.9.1-0.8.2.1 /srv/kafka
cd /srv/kafka

# on one of the zookeeper's node create the kafka's root path:
zkCli.sh -server 127.0.0.1:2181
create /kafka ''

# edit config/server.properties
sed -i "s|^\(zookeeper.connect=\).*|\1172.28.128.10:2181,172.28.128.11:2181,172.28.128.12:2181/kafka|g" /srv/kafka/config/server.properties
id=$(echo ${HOSTNAME} | tr -d '[a-z-.]')
sed -i "s/\(broker.id=\).*/\1$id/g" /srv/kafka/config/server.properties
echo "delete.topic.enable=true" >> /srv/kafka/config/server.properties

echo "PATH=$PATH:/srv/kafka/bin" >> ~/.bash_profile
. ~/.bash_profile

kafka-server-start.sh config/server.properties

# supervisord
wget https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm
yum -y localinstall epel-release-latest-7.noarch.rpm

yum -y install supervisor
systemctl enable supervisord.service
systemctl start supervisord.service

cat << EOF > /etc/supervisord.d/kafka.ini
[program:kafka]
command=/srv/kafka/bin/kafka-server-start.sh /srv/kafka/config/server.properties
autostart=true
startsecs=10
startretries=9
logfile_maxbytes=20MB
logfile_backups=10
stderr_logfile=/var/log/supervisor-kafka.err.log
stdout_logfile=/var/log/supervisor-kafka.out.log
EOF

supervisorctl reload

# some commands for testing
kafka-console-consumer.sh --zookeeper zookeeper1:2181,zookeeper2:2181,zookeeper3:2181/kafka --topic topic-1 --from-beginning

kafka-console-producer.sh --broker-list 172.28.128.16:9092,172.28.128.17:9092,172.28.128.18:9092 --topic topic-1

kafka-topics.sh --zookeeper 172.28.128.10:2181,172.28.128.11:2181,172.28.128.12:2181/kafka --describe --topic topic-1

# validate using the consumer offset checker
# create node on zookeeper
create /kafka/consumers/<consumer_group>/owners ''
kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --zookeeper 172.28.128.10:2181,172.28.128.11:2181,172.28.128.12:2181/kafka --broker-info --group <consumer_group> --topic topic-1

# every replica in ISR has all messages that are committed. A replica will be dropped out of ISR if it diverges from the leader. This is controlled by two parameters: replica.lag.time.max.ms and replica.lag.max.messages. The former is typically set to a value that reliably detects the failure of a broker. We have a min fetch rate JMX in the broker. If that rate is n, set the former to a value larger than 1/n * 1000. The latter is typically set to the observed max lag (a JMX bean) in the follower. Note that if replica.lag.max.messages is too large, it can increase the time to commit a message. If latency becomes a problem, you can increase the number of partitions in a topic. If a replica constantly drops out of and rejoins isr, you may need to increase replica.lag.max.messages. If a replica stays out of ISR for a long time, it may indicate that the follower is not able to fetch data as fast as data is accumulated at the leader. You can increase the follower's fetch throughput by setting a larger value for num.replica.fetchers

# replica.fetch.max.bytes == message.max.bytes

# ISR drops batch messages if they more than 4000 messages behind the leader
# so split them

# out of memory
replica.message.max.bytes * N of partitions the broker replicates
fetch.message.max.bytes * N of partitions the consumer reads
